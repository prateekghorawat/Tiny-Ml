{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","mount_file_id":"1VxhSQofUb-9anjisjpGQWvK5_spE3c4G","authorship_tag":"ABX9TyPYIHsHPLi+z/mpf23IOlcJ"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["pip install -q tensorflow-model-optimization"],"metadata":{"id":"npxX2BEUNagH","executionInfo":{"status":"ok","timestamp":1705156979191,"user_tz":-330,"elapsed":7240,"user":{"displayName":"Prateek Ghorawat","userId":"17376368182342777859"}}},"execution_count":28,"outputs":[]},{"cell_type":"code","execution_count":56,"metadata":{"id":"Bu3G8TNJlyPp","executionInfo":{"status":"ok","timestamp":1705158425277,"user_tz":-330,"elapsed":842,"user":{"displayName":"Prateek Ghorawat","userId":"17376368182342777859"}}},"outputs":[],"source":["import numpy as np\n","from numpy import random\n","import matplotlib.pyplot as plt\n","import tensorflow as tf\n","from tensorflow.keras.datasets import fashion_mnist\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dropout, Dense\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.utils import to_categorical\n","from tensorflow.keras.models import load_model\n","import os\n","import tensorflow_model_optimization as tfmot\n","import pathlib\n","import tempfile\n"]},{"cell_type":"code","source":["(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()"],"metadata":{"id":"e5oYcocopbo8","executionInfo":{"status":"ok","timestamp":1705156980213,"user_tz":-330,"elapsed":1027,"user":{"displayName":"Prateek Ghorawat","userId":"17376368182342777859"}}},"execution_count":30,"outputs":[]},{"cell_type":"code","source":["num_class = 10\n","X_train = X_train.astype('float32')\n","X_test = X_test.astype('float32')"],"metadata":{"id":"kyCAd3dTpeKD","executionInfo":{"status":"ok","timestamp":1705156980213,"user_tz":-330,"elapsed":8,"user":{"displayName":"Prateek Ghorawat","userId":"17376368182342777859"}}},"execution_count":31,"outputs":[]},{"cell_type":"code","source":["X_train /= 255\n","X_test /= 255\n","X_train = X_train.reshape(-1, X_train.shape[1], X_train.shape[2], 1)\n","X_test = X_test.reshape(-1, X_test.shape[1], X_test.shape[2], 1)\n","y_train = to_categorical(y_train, num_class)\n","y_test = to_categorical(y_test, num_class)"],"metadata":{"id":"G5KOcSSUqdTp","executionInfo":{"status":"ok","timestamp":1705156980213,"user_tz":-330,"elapsed":7,"user":{"displayName":"Prateek Ghorawat","userId":"17376368182342777859"}}},"execution_count":32,"outputs":[]},{"cell_type":"code","source":["model = Sequential()\n","model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape = (28,28,1)))\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","model.add(Flatten())\n","model.add(Dropout(0.5))\n","model.add(Dense(100, activation = 'relu'))\n","model.add(Dense(num_class, activation='softmax'))"],"metadata":{"id":"JRQSdEgoqkVT","executionInfo":{"status":"ok","timestamp":1705156980213,"user_tz":-330,"elapsed":6,"user":{"displayName":"Prateek Ghorawat","userId":"17376368182342777859"}}},"execution_count":33,"outputs":[]},{"cell_type":"code","source":["model.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"T-NMo5mVqq2a","executionInfo":{"status":"ok","timestamp":1705156980213,"user_tz":-330,"elapsed":6,"user":{"displayName":"Prateek Ghorawat","userId":"17376368182342777859"}},"outputId":"bc6ba098-30c8-4d9d-a115-69329640d61a"},"execution_count":34,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential_1\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv2d_2 (Conv2D)           (None, 26, 26, 32)        320       \n","                                                                 \n"," max_pooling2d_2 (MaxPoolin  (None, 13, 13, 32)        0         \n"," g2D)                                                            \n","                                                                 \n"," conv2d_3 (Conv2D)           (None, 11, 11, 64)        18496     \n","                                                                 \n"," max_pooling2d_3 (MaxPoolin  (None, 5, 5, 64)          0         \n"," g2D)                                                            \n","                                                                 \n"," flatten_1 (Flatten)         (None, 1600)              0         \n","                                                                 \n"," dropout_1 (Dropout)         (None, 1600)              0         \n","                                                                 \n"," dense_2 (Dense)             (None, 100)               160100    \n","                                                                 \n"," dense_3 (Dense)             (None, 10)                1010      \n","                                                                 \n","=================================================================\n","Total params: 179926 (702.84 KB)\n","Trainable params: 179926 (702.84 KB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n"]}]},{"cell_type":"code","source":["opt = Adam(learning_rate=0.002)\n","model.compile(loss='categorical_crossentropy', optimizer = opt, metrics=['accuracy'])"],"metadata":{"id":"vSP31o5sqt6T","executionInfo":{"status":"ok","timestamp":1705156980213,"user_tz":-330,"elapsed":3,"user":{"displayName":"Prateek Ghorawat","userId":"17376368182342777859"}}},"execution_count":35,"outputs":[]},{"cell_type":"code","source":["model.fit(X_train, y_train, batch_size=128, epochs=15)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ie3q0Ugwq0zb","executionInfo":{"status":"ok","timestamp":1705157034190,"user_tz":-330,"elapsed":53980,"user":{"displayName":"Prateek Ghorawat","userId":"17376368182342777859"}},"outputId":"0e93cd99-3a5b-447b-d337-f83a17174dc1"},"execution_count":36,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/15\n","469/469 [==============================] - 4s 6ms/step - loss: 0.5358 - accuracy: 0.8060\n","Epoch 2/15\n","469/469 [==============================] - 2s 5ms/step - loss: 0.3650 - accuracy: 0.8660\n","Epoch 3/15\n","469/469 [==============================] - 5s 10ms/step - loss: 0.3214 - accuracy: 0.8808\n","Epoch 4/15\n","469/469 [==============================] - 5s 11ms/step - loss: 0.2924 - accuracy: 0.8919\n","Epoch 5/15\n","469/469 [==============================] - 5s 10ms/step - loss: 0.2750 - accuracy: 0.8979\n","Epoch 6/15\n","469/469 [==============================] - 4s 9ms/step - loss: 0.2611 - accuracy: 0.9026\n","Epoch 7/15\n","469/469 [==============================] - 6s 14ms/step - loss: 0.2454 - accuracy: 0.9086\n","Epoch 8/15\n","469/469 [==============================] - 4s 8ms/step - loss: 0.2394 - accuracy: 0.9101\n","Epoch 9/15\n","469/469 [==============================] - 2s 5ms/step - loss: 0.2284 - accuracy: 0.9154\n","Epoch 10/15\n","469/469 [==============================] - 2s 5ms/step - loss: 0.2232 - accuracy: 0.9153\n","Epoch 11/15\n","469/469 [==============================] - 3s 6ms/step - loss: 0.2116 - accuracy: 0.9196\n","Epoch 12/15\n","469/469 [==============================] - 3s 7ms/step - loss: 0.2079 - accuracy: 0.9207\n","Epoch 13/15\n","469/469 [==============================] - 2s 5ms/step - loss: 0.2034 - accuracy: 0.9230\n","Epoch 14/15\n","469/469 [==============================] - 2s 5ms/step - loss: 0.1994 - accuracy: 0.9233\n","Epoch 15/15\n","469/469 [==============================] - 2s 5ms/step - loss: 0.1916 - accuracy: 0.9266\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.src.callbacks.History at 0x7bc88856c760>"]},"metadata":{},"execution_count":36}]},{"cell_type":"code","source":["score = model.evaluate(X_test, y_test)\n","print('accuracy on test data:', score[1])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rFwHiUayq8SI","executionInfo":{"status":"ok","timestamp":1705157035876,"user_tz":-330,"elapsed":1706,"user":{"displayName":"Prateek Ghorawat","userId":"17376368182342777859"}},"outputId":"ec0d1508-41be-4963-b83e-9c5f80efb8cf"},"execution_count":37,"outputs":[{"output_type":"stream","name":"stdout","text":["313/313 [==============================] - 1s 4ms/step - loss: 0.2326 - accuracy: 0.9152\n","accuracy on test data: 0.9151999950408936\n"]}]},{"cell_type":"code","source":["model.save('/content/drive/MyDrive/Colab_Notebooks/Hands_on_TinyML/01_Understanding_TF_Lite/baseline_model.h5')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KjgVcNLTrILj","executionInfo":{"status":"ok","timestamp":1705157035876,"user_tz":-330,"elapsed":8,"user":{"displayName":"Prateek Ghorawat","userId":"17376368182342777859"}},"outputId":"c02d2edf-4b82-4bff-82c3-162cfac798dd"},"execution_count":38,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]}]},{"cell_type":"code","source":["baseline_model = load_model('/content/drive/MyDrive/Colab_Notebooks/Hands_on_TinyML/01_Understanding_TF_Lite/baseline_model.h5')"],"metadata":{"id":"a8iqjJY_rMey","executionInfo":{"status":"ok","timestamp":1705157037038,"user_tz":-330,"elapsed":1167,"user":{"displayName":"Prateek Ghorawat","userId":"17376368182342777859"}}},"execution_count":39,"outputs":[]},{"cell_type":"markdown","source":["## **Converting to TFLite model**"],"metadata":{"id":"wOq05tUTrddB"}},{"cell_type":"markdown","source":["### **Way to Convert**\n","* We can do the conversion using\n"," **tf.lite.TFLiteConverter**. We will call the **from_keras_model()** method under the\n"," **tf.lite.TFLiteConverte**r class and pass the baseline model as a function argument."],"metadata":{"id":"e95WxPLrzwAZ"}},{"cell_type":"code","source":["convertor = tf.lite.TFLiteConverter.from_keras_model(baseline_model)\n","tflite_model = convertor.convert()"],"metadata":{"id":"SwIlwhI5rnWa","executionInfo":{"status":"ok","timestamp":1705157038073,"user_tz":-330,"elapsed":2202,"user":{"displayName":"Prateek Ghorawat","userId":"17376368182342777859"}}},"execution_count":40,"outputs":[]},{"cell_type":"markdown","source":["**Note :**\n","* We can further convert the baseline model to a TensorFlow graph using **tf.function**,\n","which contains all the computational operations, variables, and weights. This can be\n","achieved by exporting the model as a concrete function. Finally, the concrete function\n","is converted into a TFLite model using the method from_concrete_functions()."],"metadata":{"id":"5XQUcYTs0r6G"}},{"cell_type":"code","source":["func = tf.function(baseline_model).get_concrete_function(tf.TensorSpec(baseline_model.inputs[0].shape , baseline_model.inputs[0].dtype))\n","func.graph.as_graph_def()\n","converter =  tf.lite.TFLiteConverter.from_concrete_functions([func])\n","tflite_model = converter.convert()"],"metadata":{"id":"AHL0DUZ_r_cZ","executionInfo":{"status":"ok","timestamp":1705157038074,"user_tz":-330,"elapsed":9,"user":{"displayName":"Prateek Ghorawat","userId":"17376368182342777859"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"ea4507bc-2454-4fe9-9941-5d06c210c22d"},"execution_count":41,"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:absl:Please consider providing the trackable_obj argument in the from_concrete_functions. Providing without the trackable_obj argument is deprecated and it will use the deprecated conversion path.\n"]}]},{"cell_type":"code","source":["path = \"/content/drive/MyDrive/Colab_Notebooks/Hands_on_TinyML/01_Understanding_TF_Lite/tg_lite_model\"\n","\n","tflite_models_dir = pathlib.Path(path)\n","tflite_models_dir.mkdir(exist_ok=True, parents=True)\n","tflite_model_file = tflite_models_dir/'model.tflite'\n","tflite_model_file.write_bytes(tflite_model)"],"metadata":{"id":"ZeSFEGeTxPVL","executionInfo":{"status":"ok","timestamp":1705157038074,"user_tz":-330,"elapsed":6,"user":{"displayName":"Prateek Ghorawat","userId":"17376368182342777859"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"e7b0b35f-709c-4d92-87ea-398b14585fbd"},"execution_count":42,"outputs":[{"output_type":"execute_result","data":{"text/plain":["723092"]},"metadata":{},"execution_count":42}]},{"cell_type":"markdown","source":["**Now, we have a TFLite model. We will use it to make inferences in Python**. This can\n","be done by using the tf.lite.Interpreter class.\n","The following steps are done to make an inference in TensorFlow Lite:\n","1. First, we create an instance of the Interpreter class. It takes the path\n","containing the .TFLIE file as an input.\n","2. Allocate memory to the Interpreter by calling the function allocate_\n","tensors().\n","3. After memory allocation, call get_input_details() and get_output_\n","details() to get some details about the input and the output tensor.\n","4. Now, we are ready to make inferences. Get an image from the test data and\n","reshape it according to the desired input shape to the model.\n","5. Set the input tensor by copying the input data. Use the method set_tensor().\n","6. Invoke the interpreter to make an inference by calling Interpreter.invoke().\n","7. Get the value of the output tensor.\n","8. Covert it into the predicted class label"],"metadata":{"id":"YzUqFTMaxSmV"}},{"cell_type":"code","source":["tflite_model = \"/content/drive/MyDrive/Colab_Notebooks/Hands_on_TinyML/01_Understanding_TF_Lite/tg_lite_model/model.tflite\"\n","interpreter = tf.lite.Interpreter(model_path = tflite_model )\n","interpreter.allocate_tensors()\n","input_index = interpreter.get_input_details()[0]['index']\n","output_index = interpreter.get_output_details()[0]['index']\n","pred_list = []\n","for images in X_test:\n","  input_data = np.array(images, dtype=np.float32)\n","\n","  input_data = input_data.reshape(1, input_data.shape[0], input_data.shape[1], 1)\n","\n","  interpreter.set_tensor(input_index, input_data)\n","  interpreter.invoke()\n","  prediction = interpreter.get_tensor(output_index)\n","  prediction = np.argmax(prediction)\n","  pred_list.append(prediction)\n","\n","accurate_count = 0\n","for index in range(len(pred_list)):\n","  if pred_list[index] == np.argmax(y_test[index]):\n","      accurate_count += 1\n","accuracy = accurate_count * 1.0 / len(pred_list)\n","\n","print('accuracy = ', accuracy)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"m4W62XjMFwjK","executionInfo":{"status":"ok","timestamp":1705157040549,"user_tz":-330,"elapsed":2479,"user":{"displayName":"Prateek Ghorawat","userId":"17376368182342777859"}},"outputId":"4ac6e63f-c2ac-4b17-efe1-694158094b95"},"execution_count":43,"outputs":[{"output_type":"stream","name":"stdout","text":["accuracy =  0.9152\n"]}]},{"cell_type":"markdown","source":["---"],"metadata":{"id":"7egY8bU8Gytt"}},{"cell_type":"markdown","source":["### **Tensorflow model optimization**\n","The TensorFlow Model Optimization Toolkit consists of a set of libraries for the\n","effective optimization of large neural networks. The primary goal of optimization is\n","to enable a large machine learning model to seamlessly run on smaller edge devices\n","having restricted hardware resources in terms of memory and computational\n","capacity. They also need to consume lower battery power on the target hardware.\n","Such applications are particularly useful in scenarios where we require continuous\n","24 × 7 monitoring, for example, machine condition monitoring in large industries,\n","on-device cardiac health monitoring systems, smart voice assistant devices, and so\n","on. A few popular model optimizations techniques are as follows:\n","\n","• Lowering the precision of model weights and activations\n","\n","• Reducing some of the lesser important parameters in the model\n","\n","• Updating the model topology"],"metadata":{"id":"tXeerEHGG1WU"}},{"cell_type":"markdown","source":["### **Optimization Techniques**\n","* **Quantization** is an optimization strategy used to lower the precision of a machine\n","learning model. Both model weights and activation outputs can be quantized in the\n","process. Integer-based quantization is particularly common in TinyML. It converts\n","the weights and activation outputs from the original 32-bit floating point numbers\n","to the nearest 8-bit fixed-point numbers. As a result, the model size is reduced by\n","a factor of 4. The resulting model also has a faster inference speed. Quantization is\n","particularly common in low-powered microcontroller devices, as many of them do\n","not have floating-point units in the hardware.\n","  *  post-training quantization\n","  * quantization-aware training\n","\n"],"metadata":{"id":"b5BwPkt4HR3M"}},{"cell_type":"code","source":["converter = tf.lite.TFLiteConverter.from_keras_model(baseline_model)\n","converter.optimizations = [tf.lite.Optimize.DEFAULT]\n","tflite_model_ptq = converter.convert()"],"metadata":{"id":"Hyqw5CIKLFot","executionInfo":{"status":"ok","timestamp":1705157042982,"user_tz":-330,"elapsed":2437,"user":{"displayName":"Prateek Ghorawat","userId":"17376368182342777859"}}},"execution_count":44,"outputs":[]},{"cell_type":"code","source":["tflite_models_dir = pathlib.Path(\"/content/drive/MyDrive/Colab_Notebooks/Hands_on_TinyML/01_Understanding_TF_Lite/tg_lite_model\")\n","tflite_models_dir.mkdir(exist_ok=True, parents=True)\n","tflite_model_file = tflite_models_dir/\"model_ptq.tflite\"\n","tflite_model_file.write_bytes(tflite_model_ptq)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"71iifl97LmJb","executionInfo":{"status":"ok","timestamp":1705157042982,"user_tz":-330,"elapsed":5,"user":{"displayName":"Prateek Ghorawat","userId":"17376368182342777859"}},"outputId":"7c43d270-f5d3-41ac-fe3a-d033013da4c1"},"execution_count":45,"outputs":[{"output_type":"execute_result","data":{"text/plain":["188760"]},"metadata":{},"execution_count":45}]},{"cell_type":"code","source":["tflite_model_file = \"/content/drive/MyDrive/Colab_Notebooks/Hands_on_TinyML/01_Understanding_TF_Lite/tg_lite_model/model_ptq.tflite\"\n","interpreter = tf.lite.Interpreter(model_path=tflite_model_file)\n","interpreter.allocate_tensors()\n","\n","input_index = interpreter.get_input_details()[0][\"index\"]\n","output_index = interpreter.get_output_details()[0][\"index\"]\n","\n","pred_list = []\n","for images in X_test:\n","  input_data = np.array(images, dtype=np.float32)\n","\n","  input_data = input_data.reshape(1, input_data.shape[0], input_data.shape[1], 1)\n","\n","  interpreter.set_tensor(input_index, input_data)\n","  interpreter.invoke()\n","  prediction = interpreter.get_tensor(output_index)\n","  prediction = np.argmax(prediction)\n","  pred_list.append(prediction)\n","\n","accurate_count = 0\n","for index in range(len(pred_list)):\n","  if pred_list[index] == np.argmax(y_test[index]):\n","      accurate_count += 1\n","accuracy = accurate_count * 1.0 / len(pred_list)\n","\n","print(accuracy)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LtSbzAsiLtAK","executionInfo":{"status":"ok","timestamp":1705157045496,"user_tz":-330,"elapsed":2517,"user":{"displayName":"Prateek Ghorawat","userId":"17376368182342777859"}},"outputId":"8ab3a1b6-4e0b-4c44-db8d-a33fa76daf47"},"execution_count":46,"outputs":[{"output_type":"stream","name":"stdout","text":["0.9151\n"]}]},{"cell_type":"markdown","source":["**Quantization-aware training**\n","In post-training quantization, we take a pre-trained model and convert the weights\n","and activation output into 8-bit integers. One major disadvantage is that we do not\n","fine-tune the model after quantization. In most of the cases, lowering the precision\n","of the model weights will introduce a loss called quantization error. This can have\n","a negative impact on model performance. Quantization-aware training tries to\n","minimize the loss via backpropagation by retraining the model for few epochs. By\n","doing this, it mitigates the impact of quantization error to some extent."],"metadata":{"id":"pScfMopkMHph"}},{"cell_type":"code","source":["baseline_model = load_model('/content/drive/MyDrive/Colab_Notebooks/Hands_on_TinyML/01_Understanding_TF_Lite/baseline_model.h5')\n","\n","quantized_model = tfmot.quantization.keras.quantize_model\n","q_aware_model = quantized_model(baseline_model)\n","q_aware_model.compile(optimizer='adam',\n","              loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n","              metrics=['accuracy'])\n","\n","q_aware_model.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"j6EsUvzBNLY9","executionInfo":{"status":"ok","timestamp":1705157046968,"user_tz":-330,"elapsed":1476,"user":{"displayName":"Prateek Ghorawat","userId":"17376368182342777859"}},"outputId":"a567e5bc-2d63-437b-c11a-b322074386ac"},"execution_count":47,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential_1\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," quantize_layer_1 (Quantize  (None, 28, 28, 1)         3         \n"," Layer)                                                          \n","                                                                 \n"," quant_conv2d_2 (QuantizeWr  (None, 26, 26, 32)        387       \n"," apperV2)                                                        \n","                                                                 \n"," quant_max_pooling2d_2 (Qua  (None, 13, 13, 32)        1         \n"," ntizeWrapperV2)                                                 \n","                                                                 \n"," quant_conv2d_3 (QuantizeWr  (None, 11, 11, 64)        18627     \n"," apperV2)                                                        \n","                                                                 \n"," quant_max_pooling2d_3 (Qua  (None, 5, 5, 64)          1         \n"," ntizeWrapperV2)                                                 \n","                                                                 \n"," quant_flatten_1 (QuantizeW  (None, 1600)              1         \n"," rapperV2)                                                       \n","                                                                 \n"," quant_dropout_1 (QuantizeW  (None, 1600)              1         \n"," rapperV2)                                                       \n","                                                                 \n"," quant_dense_2 (QuantizeWra  (None, 100)               160105    \n"," pperV2)                                                         \n","                                                                 \n"," quant_dense_3 (QuantizeWra  (None, 10)                1015      \n"," pperV2)                                                         \n","                                                                 \n","=================================================================\n","Total params: 180141 (703.68 KB)\n","Trainable params: 179926 (702.84 KB)\n","Non-trainable params: 215 (860.00 Byte)\n","_________________________________________________________________\n"]}]},{"cell_type":"markdown","source":["**Note** that the resulting model is\n","only quantization-aware but not yet quantized. The floating point model weights\n","and activations are rounded to mimic integer values. Before converting them into\n","full-integer, we will retrain to fine-tune the model."],"metadata":{"id":"MxuqgRbhO3E2"}},{"cell_type":"code","source":["q_aware_model.fit(X_train, y_train, batch_size=500, epochs=2, validation_split=0.1)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HZS7v3cINv-A","executionInfo":{"status":"ok","timestamp":1705157058389,"user_tz":-330,"elapsed":11424,"user":{"displayName":"Prateek Ghorawat","userId":"17376368182342777859"}},"outputId":"67904352-d456-485b-cc1b-dda491deaea4"},"execution_count":48,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/2\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/backend.py:5575: UserWarning: \"`categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Softmax activation and thus does not represent logits. Was this intended?\n","  output, from_logits = _get_logits(\n"]},{"output_type":"stream","name":"stdout","text":["108/108 [==============================] - 7s 37ms/step - loss: 0.1730 - accuracy: 0.9344 - val_loss: 0.1238 - val_accuracy: 0.9550\n","Epoch 2/2\n","108/108 [==============================] - 4s 37ms/step - loss: 0.1608 - accuracy: 0.9389 - val_loss: 0.1207 - val_accuracy: 0.9567\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.src.callbacks.History at 0x7bc88915fac0>"]},"metadata":{},"execution_count":48}]},{"cell_type":"code","source":["converter = tf.lite.TFLiteConverter.from_keras_model(q_aware_model)\n","converter.optimizations = [tf.lite.Optimize.DEFAULT]\n","tflite_model_qat = converter.convert()\n","\n","tflite_models_dir = pathlib.Path(\"/content/drive/MyDrive/Colab_Notebooks/Hands_on_TinyML/01_Understanding_TF_Lite/tg_lite_model\")\n","tflite_models_dir.mkdir(exist_ok=True, parents=True)\n","tflite_model_file = tflite_models_dir/\"model_qat.tflite\"\n","tflite_model_file.write_bytes(tflite_model_qat)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"88XzKacxN9PI","executionInfo":{"status":"ok","timestamp":1705157065726,"user_tz":-330,"elapsed":7350,"user":{"displayName":"Prateek Ghorawat","userId":"17376368182342777859"}},"outputId":"d068fe87-075e-4a20-d1dd-8d638c2f106a"},"execution_count":49,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/tensorflow/lite/python/convert.py:953: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n","  warnings.warn(\n"]},{"output_type":"execute_result","data":{"text/plain":["187888"]},"metadata":{},"execution_count":49}]},{"cell_type":"code","source":["tflite_model_file = '/content/drive/MyDrive/Colab_Notebooks/Hands_on_TinyML/01_Understanding_TF_Lite/tg_lite_model/model_qat.tflite'\n","interpreter = tf.lite.Interpreter(model_path=tflite_model_file)\n","interpreter.allocate_tensors()\n","\n","input_index = interpreter.get_input_details()[0][\"index\"]\n","output_index = interpreter.get_output_details()[0][\"index\"]\n","\n","pred_list = []\n","for images in X_test:\n","  input_data = np.array(images, dtype=np.float32)\n","\n","  input_data = input_data.reshape(1, input_data.shape[0], input_data.shape[1], 1)\n","\n","  interpreter.set_tensor(input_index, input_data)\n","  interpreter.invoke()\n","  prediction = interpreter.get_tensor(output_index)\n","  prediction = np.argmax(prediction)\n","  pred_list.append(prediction)\n","\n","accurate_count = 0\n","for index in range(len(pred_list)):\n","  if pred_list[index] == np.argmax(y_test[index]):\n","      accurate_count += 1\n","accuracy = accurate_count * 1.0 / len(pred_list)\n","\n","print('accuracy = ', accuracy)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cx5S0ABFPT5A","executionInfo":{"status":"ok","timestamp":1705157067153,"user_tz":-330,"elapsed":1438,"user":{"displayName":"Prateek Ghorawat","userId":"17376368182342777859"}},"outputId":"306f1fb3-f6d2-4f3c-92b2-4813b36f926b"},"execution_count":50,"outputs":[{"output_type":"stream","name":"stdout","text":["accuracy =  0.9201\n"]}]},{"cell_type":"markdown","source":["**Important Note** : A fully quantized\n","model can often be less accurate compared to the baseline model, even after\n","retraining. To mitigate that risk, the critical feature extraction layers are often not\n","quantized in a deep neural network. For example, you may prefer to quantize only\n","the first few convolutional layers of a CNN."],"metadata":{"id":"G6deaPoXPdw2"}},{"cell_type":"markdown","source":["***we will quantize only the dense layers of the baseline CNN.\n","We will first define a function apply_quantization(layer) to define which layers\n","will be quantized. Next, we will use tf.keras.models.clone_model to apply\n","quantization to the dense layers by calling the function.***"],"metadata":{"id":"M2rQpCH7PskH"}},{"cell_type":"code","source":["baseline_model = load_model('/content/drive/MyDrive/Colab_Notebooks/Hands_on_TinyML/01_Understanding_TF_Lite/baseline_model.h5')\n","\n","def apply_quantization(layer):\n","      if isinstance(layer, tf.keras.layers.Dense):\n","        return tfmot.quantization.keras.quantize_annotate_layer(layer)\n","      return layer\n","annotated_model = tf.keras.models.clone_model(baseline_model,clone_function=apply_quantization,)\n","q_aware_model_dense = tfmot.quantization.keras.quantize_apply(annotated_model)\n","q_aware_model_dense.summary()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pcYLCVCfP8PN","executionInfo":{"status":"ok","timestamp":1705157068020,"user_tz":-330,"elapsed":871,"user":{"displayName":"Prateek Ghorawat","userId":"17376368182342777859"}},"outputId":"54794dd1-981e-47c6-868c-d37b42b2bbe9"},"execution_count":51,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential_1\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv2d_2 (Conv2D)           (None, 26, 26, 32)        320       \n","                                                                 \n"," max_pooling2d_2 (MaxPoolin  (None, 13, 13, 32)        0         \n"," g2D)                                                            \n","                                                                 \n"," conv2d_3 (Conv2D)           (None, 11, 11, 64)        18496     \n","                                                                 \n"," max_pooling2d_3 (MaxPoolin  (None, 5, 5, 64)          0         \n"," g2D)                                                            \n","                                                                 \n"," flatten_1 (Flatten)         (None, 1600)              0         \n","                                                                 \n"," quant_dropout_1 (QuantizeW  (None, 1600)              1         \n"," rapperV2)                                                       \n","                                                                 \n"," quant_dense_2 (QuantizeWra  (None, 100)               160105    \n"," pperV2)                                                         \n","                                                                 \n"," quant_dense_3 (QuantizeWra  (None, 10)                1015      \n"," pperV2)                                                         \n","                                                                 \n","=================================================================\n","Total params: 179937 (702.88 KB)\n","Trainable params: 179926 (702.84 KB)\n","Non-trainable params: 11 (44.00 Byte)\n","_________________________________________________________________\n"]}]},{"cell_type":"code","source":["q_aware_model_dense.compile(optimizer='adam',\n","              loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n","              metrics=['accuracy'])\n","\n","q_aware_model_dense.fit(X_train, y_train,\n","                  batch_size=500, epochs=2, validation_split=0.1)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6fgULTJXQgdR","executionInfo":{"status":"ok","timestamp":1705157073092,"user_tz":-330,"elapsed":5077,"user":{"displayName":"Prateek Ghorawat","userId":"17376368182342777859"}},"outputId":"8ed961d1-128b-4e7c-a3c0-c2765cfdcdac"},"execution_count":52,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/2\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/backend.py:5575: UserWarning: \"`categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Softmax activation and thus does not represent logits. Was this intended?\n","  output, from_logits = _get_logits(\n"]},{"output_type":"stream","name":"stdout","text":["108/108 [==============================] - 4s 18ms/step - loss: 0.1694 - accuracy: 0.9377 - val_loss: 0.1213 - val_accuracy: 0.9562\n","Epoch 2/2\n","108/108 [==============================] - 1s 13ms/step - loss: 0.1548 - accuracy: 0.9415 - val_loss: 0.1186 - val_accuracy: 0.9543\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.src.callbacks.History at 0x7bc88856d6c0>"]},"metadata":{},"execution_count":52}]},{"cell_type":"code","source":["converter = tf.lite.TFLiteConverter.from_keras_model(q_aware_model_dense)\n","converter.optimizations = [tf.lite.Optimize.DEFAULT]\n","tflite_model_qat_dense = converter.convert()\n","\n","tflite_models_dir = pathlib.Path(\"/content/drive/MyDrive/Colab_Notebooks/Hands_on_TinyML/01_Understanding_TF_Lite/tg_lite_model\")\n","tflite_models_dir.mkdir(exist_ok=True, parents=True)\n","tflite_model_file = tflite_models_dir/\"model_qat_dense.tflite\"\n","tflite_model_file.write_bytes(tflite_model_qat_dense)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"APVJ382fQxlW","executionInfo":{"status":"ok","timestamp":1705157075455,"user_tz":-330,"elapsed":2375,"user":{"displayName":"Prateek Ghorawat","userId":"17376368182342777859"}},"outputId":"9ca1cad2-19f1-4819-e907-8edeba8cb562"},"execution_count":53,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/tensorflow/lite/python/convert.py:953: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n","  warnings.warn(\n"]},{"output_type":"execute_result","data":{"text/plain":["721152"]},"metadata":{},"execution_count":53}]},{"cell_type":"code","source":["tflite_model_file = '/content/drive/MyDrive/Colab_Notebooks/Hands_on_TinyML/01_Understanding_TF_Lite/tg_lite_model/model_qat_dense.tflite'\n","interpreter = tf.lite.Interpreter(model_path=tflite_model_file)\n","interpreter.allocate_tensors()\n","\n","input_index = interpreter.get_input_details()[0][\"index\"]\n","output_index = interpreter.get_output_details()[0][\"index\"]\n","\n","pred_list = []\n","for images in X_test:\n","  input_data = np.array(images, dtype=np.float32)\n","\n","  input_data = input_data.reshape(1, input_data.shape[0], input_data.shape[1], 1)\n","\n","  interpreter.set_tensor(input_index, input_data)\n","  interpreter.invoke()\n","  prediction = interpreter.get_tensor(output_index)\n","  prediction = np.argmax(prediction)\n","  pred_list.append(prediction)\n","\n","accurate_count = 0\n","for index in range(len(pred_list)):\n","  if pred_list[index] == np.argmax(y_test[index]):\n","      accurate_count += 1\n","accuracy = accurate_count * 1.0 / len(pred_list)\n","\n","print('accuracy = ', accuracy)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"h7Ju4TmORSjZ","executionInfo":{"status":"ok","timestamp":1705157076980,"user_tz":-330,"elapsed":1528,"user":{"displayName":"Prateek Ghorawat","userId":"17376368182342777859"}},"outputId":"719872ea-50fc-48b3-fb86-2ba187af8862"},"execution_count":54,"outputs":[{"output_type":"stream","name":"stdout","text":["accuracy =  0.9236\n"]}]},{"cell_type":"markdown","source":["---\n","\n","**Weight pruning** is another popular model optimization technique that zeros out\n","some of the less significant model weights. The pruned elements are trimmed\n","from the model to introduce sparsity. Such sparse models are easy to compress and\n","occupy lesser memory space in the target device. During inference, the zero weights\n","are skipped, resulting in an improved latency due to lesser mathematical operations.\n","\n","\n","**Process:**\n","\n","1. **Magnitude-based Pruning:**\n","   - Consider absolute values of weights.\n","   - Absolute values help focus on the importance of the weight, regardless of its direction (positive or negative).\n","\n","2. **Setting a Threshold:**\n","   - Choose a threshold value.\n","   - Connections with weights below this threshold are considered less important.\n","\n","3. **Zeroing Out Weights:**\n","   - Set to zero (prune) connections with weights below the threshold.\n","   - These pruned connections won't contribute to the network's computations.\n","\n","**Example:**\n","\n","Let's illustrate with a connection having a weight of -0.2. The absolute value is 0.2. If the threshold is set at 0.3, this connection would be pruned because 0.2 is below the threshold.\n","\n","**Trade-off:**\n","\n","- Weight pruning creates a sparser network, reducing the number of connections.\n","- Too much pruning can impact model performance.\n","- A balance between model size and accuracy must be maintained.\n","\n","In summary, weight pruning is like cleaning up unnecessary connections, keeping important ones, and finding a trade-off between a compact model and good performance.\n","\n","---"],"metadata":{"id":"ctPfKb7oRZ2l"}},{"cell_type":"code","source":[],"metadata":{"id":"_KIoWwF0RX2s","executionInfo":{"status":"ok","timestamp":1705157076980,"user_tz":-330,"elapsed":6,"user":{"displayName":"Prateek Ghorawat","userId":"17376368182342777859"}}},"execution_count":54,"outputs":[]},{"cell_type":"code","source":["prune_low_magnitude = tfmot.sparsity.keras.prune_low_magnitude\n","\n","batch_size = 128\n","epochs = 2\n","validation_split = 0.1\n","\n","num_samples = X_train.shape[0] * (1 - validation_split)\n","end_step = np.ceil(num_samples / batch_size).astype(np.int32) * epochs\n","\n","pruning_params = {\n","      'pruning_schedule': tfmot.sparsity.keras.PolynomialDecay(initial_sparsity=0.40,\n","                                                               final_sparsity=0.75,\n","                                                               begin_step=0,\n","                                                               end_step=end_step) # This function is used to define the loop iterations\n","}\n","\n","model_for_pruning = prune_low_magnitude(baseline_model, **pruning_params)\n","\n","model_for_pruning.compile(optimizer='adam',\n","              loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n","              metrics=['accuracy'])\n","\n","model_for_pruning.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"W9jEDlQJN3mi","executionInfo":{"status":"ok","timestamp":1705158393178,"user_tz":-330,"elapsed":991,"user":{"displayName":"Prateek Ghorawat","userId":"17376368182342777859"}},"outputId":"86fa9feb-1e80-45a3-f0bd-b6c4fb4e592e"},"execution_count":55,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential_1\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," prune_low_magnitude_conv2d  (None, 26, 26, 32)        610       \n"," _2 (PruneLowMagnitude)                                          \n","                                                                 \n"," prune_low_magnitude_max_po  (None, 13, 13, 32)        1         \n"," oling2d_2 (PruneLowMagnitu                                      \n"," de)                                                             \n","                                                                 \n"," prune_low_magnitude_conv2d  (None, 11, 11, 64)        36930     \n"," _3 (PruneLowMagnitude)                                          \n","                                                                 \n"," prune_low_magnitude_max_po  (None, 5, 5, 64)          1         \n"," oling2d_3 (PruneLowMagnitu                                      \n"," de)                                                             \n","                                                                 \n"," prune_low_magnitude_flatte  (None, 1600)              1         \n"," n_1 (PruneLowMagnitude)                                         \n","                                                                 \n"," prune_low_magnitude_dropou  (None, 1600)              1         \n"," t_1 (PruneLowMagnitude)                                         \n","                                                                 \n"," prune_low_magnitude_dense_  (None, 100)               320102    \n"," 2 (PruneLowMagnitude)                                           \n","                                                                 \n"," prune_low_magnitude_dense_  (None, 10)                2012      \n"," 3 (PruneLowMagnitude)                                           \n","                                                                 \n","=================================================================\n","Total params: 359658 (1.37 MB)\n","Trainable params: 179926 (702.84 KB)\n","Non-trainable params: 179732 (702.11 KB)\n","_________________________________________________________________\n"]}]},{"cell_type":"code","source":["log_dir = tempfile.mkdtemp()\n","callbacks = [\n","    tfmot.sparsity.keras.UpdatePruningStep(),\n","    tfmot.sparsity.keras.PruningSummaries(log_dir=log_dir)\n","]\n","\n","model_for_pruning.fit(X_train, y_train,\n","                  batch_size=batch_size, epochs=epochs, validation_split=validation_split,\n","                  callbacks=callbacks)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_MsXxaX6XDei","executionInfo":{"status":"ok","timestamp":1705158506674,"user_tz":-330,"elapsed":20489,"user":{"displayName":"Prateek Ghorawat","userId":"17376368182342777859"}},"outputId":"97c5007d-83e7-4279-d295-040d1349c400"},"execution_count":57,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/2\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/backend.py:5575: UserWarning: \"`categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Softmax activation and thus does not represent logits. Was this intended?\n","  output, from_logits = _get_logits(\n"]},{"output_type":"stream","name":"stdout","text":["\r  1/422 [..............................] - ETA: 55:54 - loss: 0.2571 - accuracy: 0.9219"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0069s vs `on_train_batch_end` time: 0.0151s). Check your callbacks.\n"]},{"output_type":"stream","name":"stdout","text":["422/422 [==============================] - 14s 15ms/step - loss: 0.2689 - accuracy: 0.8977 - val_loss: 0.2580 - val_accuracy: 0.9043\n","Epoch 2/2\n","422/422 [==============================] - 4s 10ms/step - loss: 0.2787 - accuracy: 0.8935 - val_loss: 0.2187 - val_accuracy: 0.9198\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.src.callbacks.History at 0x7bc8894b48e0>"]},"metadata":{},"execution_count":57}]},{"cell_type":"code","source":["model_for_export = tfmot.sparsity.keras.strip_pruning(model_for_pruning)"],"metadata":{"id":"6dLfi_F7XabP","executionInfo":{"status":"ok","timestamp":1705159453648,"user_tz":-330,"elapsed":503,"user":{"displayName":"Prateek Ghorawat","userId":"17376368182342777859"}}},"execution_count":58,"outputs":[]},{"cell_type":"code","source":["converter = tf.lite.TFLiteConverter.from_keras_model(model_for_export)\n","tflite_model_pruned_dense = converter.convert()\n","\n","tflite_models_dir = pathlib.Path(\"/content/drive/MyDrive/Colab_Notebooks/Hands_on_TinyML/01_Understanding_TF_Lite/tg_lite_model\")\n","tflite_models_dir.mkdir(exist_ok=True, parents=True)\n","tflite_model_file = tflite_models_dir/\"model_pruned.tflite\"\n","tflite_model_file.write_bytes(tflite_model_pruned_dense)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0XO6L_O8bGgu","executionInfo":{"status":"ok","timestamp":1705159616459,"user_tz":-330,"elapsed":3803,"user":{"displayName":"Prateek Ghorawat","userId":"17376368182342777859"}},"outputId":"ccbe2a76-3108-46e7-801e-7c40fc9b0b52"},"execution_count":60,"outputs":[{"output_type":"execute_result","data":{"text/plain":["723188"]},"metadata":{},"execution_count":60}]},{"cell_type":"code","source":["tflite_model_file = '/content/drive/MyDrive/Colab_Notebooks/Hands_on_TinyML/01_Understanding_TF_Lite/tg_lite_model/model_pruned.tflite'\n","interpreter = tf.lite.Interpreter(model_path=tflite_model_file)\n","interpreter.allocate_tensors()\n","\n","input_index = interpreter.get_input_details()[0][\"index\"]\n","output_index = interpreter.get_output_details()[0][\"index\"]\n","\n","pred_list = []\n","for images in X_test:\n","  input_data = np.array(images, dtype=np.float32)\n","\n","  input_data = input_data.reshape(1, input_data.shape[0], input_data.shape[1], 1)\n","\n","  interpreter.set_tensor(input_index, input_data)\n","  interpreter.invoke()\n","  prediction = interpreter.get_tensor(output_index)\n","  prediction = np.argmax(prediction)\n","  pred_list.append(prediction)\n","\n","accurate_count = 0\n","for index in range(len(pred_list)):\n","  if pred_list[index] == np.argmax(y_test[index]):\n","      accurate_count += 1\n","accuracy = accurate_count * 1.0 / len(pred_list)\n","\n","print(accuracy)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1k6z7Y8abZEr","executionInfo":{"status":"ok","timestamp":1705159681640,"user_tz":-330,"elapsed":3278,"user":{"displayName":"Prateek Ghorawat","userId":"17376368182342777859"}},"outputId":"2c6bac04-fc7d-4038-89b0-ed7155f9763d"},"execution_count":61,"outputs":[{"output_type":"stream","name":"stdout","text":["0.902\n"]}]},{"cell_type":"code","source":["def apply_pruning(layer):\n","  if isinstance(layer, tf.keras.layers.Dense):\n","    return tfmot.sparsity.keras.prune_low_magnitude(layer)\n","  return layer\n","\n","model_for_pruning = tf.keras.models.clone_model(\n","    baseline_model,\n","    clone_function=apply_pruning)\n","\n","model_for_pruning.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rBd5gn4_b9ZH","executionInfo":{"status":"ok","timestamp":1705159785941,"user_tz":-330,"elapsed":516,"user":{"displayName":"Prateek Ghorawat","userId":"17376368182342777859"}},"outputId":"8320c09a-8c7c-40b0-dc61-aa29c89d6318"},"execution_count":62,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential_1\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv2d_2 (Conv2D)           (None, 26, 26, 32)        320       \n","                                                                 \n"," max_pooling2d_2 (MaxPoolin  (None, 13, 13, 32)        0         \n"," g2D)                                                            \n","                                                                 \n"," conv2d_3 (Conv2D)           (None, 11, 11, 64)        18496     \n","                                                                 \n"," max_pooling2d_3 (MaxPoolin  (None, 5, 5, 64)          0         \n"," g2D)                                                            \n","                                                                 \n"," flatten_1 (Flatten)         (None, 1600)              0         \n","                                                                 \n"," dropout_1 (Dropout)         (None, 1600)              0         \n","                                                                 \n"," prune_low_magnitude_dense_  (None, 100)               320102    \n"," 2 (PruneLowMagnitude)                                           \n","                                                                 \n"," prune_low_magnitude_dense_  (None, 10)                2012      \n"," 3 (PruneLowMagnitude)                                           \n","                                                                 \n","=================================================================\n","Total params: 340930 (1.30 MB)\n","Trainable params: 179926 (702.84 KB)\n","Non-trainable params: 161004 (628.93 KB)\n","_________________________________________________________________\n"]}]},{"cell_type":"code","source":["model_for_pruning.compile(optimizer='adam',\n","              loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n","              metrics=['accuracy'])\n","\n","log_dir = tempfile.mkdtemp()\n","callbacks = [\n","    tfmot.sparsity.keras.UpdatePruningStep(),\n","    tfmot.sparsity.keras.PruningSummaries(log_dir=log_dir)\n","]\n","\n","model_for_pruning.fit(X_train, y_train,\n","                  batch_size=batch_size, epochs=epochs, validation_split=validation_split,\n","                  callbacks=callbacks)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VVgfnpvwcXnH","executionInfo":{"status":"ok","timestamp":1705159834404,"user_tz":-330,"elapsed":12224,"user":{"displayName":"Prateek Ghorawat","userId":"17376368182342777859"}},"outputId":"b6fb2db0-050d-4aa5-cc06-083fae0ec73a"},"execution_count":63,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/2\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/backend.py:5575: UserWarning: \"`categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Softmax activation and thus does not represent logits. Was this intended?\n","  output, from_logits = _get_logits(\n"]},{"output_type":"stream","name":"stdout","text":["  6/422 [..............................] - ETA: 4s - loss: 0.3222 - accuracy: 0.8802   "]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0087s vs `on_train_batch_end` time: 0.0121s). Check your callbacks.\n"]},{"output_type":"stream","name":"stdout","text":["422/422 [==============================] - 7s 10ms/step - loss: 0.2449 - accuracy: 0.9074 - val_loss: 0.1898 - val_accuracy: 0.9283\n","Epoch 2/2\n","422/422 [==============================] - 3s 7ms/step - loss: 0.2172 - accuracy: 0.9180 - val_loss: 0.1842 - val_accuracy: 0.9315\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.src.callbacks.History at 0x7bc889283df0>"]},"metadata":{},"execution_count":63}]},{"cell_type":"code","source":["model_for_export = tfmot.sparsity.keras.strip_pruning(model_for_pruning)\n","\n","converter = tf.lite.TFLiteConverter.from_keras_model(model_for_export)\n","tflite_model_pruned_dense = converter.convert()"],"metadata":{"id":"67pNFrBdcgl7","executionInfo":{"status":"ok","timestamp":1705159851161,"user_tz":-330,"elapsed":2358,"user":{"displayName":"Prateek Ghorawat","userId":"17376368182342777859"}}},"execution_count":64,"outputs":[]},{"cell_type":"code","source":["tflite_models_dir = pathlib.Path(\"/content/drive/MyDrive/Colab_Notebooks/Hands_on_TinyML/01_Understanding_TF_Lite/tg_lite_model\")\n","tflite_models_dir.mkdir(exist_ok=True, parents=True)\n","tflite_model_file = tflite_models_dir/\"model_pruned_dense.tflite\"\n","tflite_model_file.write_bytes(tflite_model_pruned_dense)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"woQojVWUcnBc","executionInfo":{"status":"ok","timestamp":1705159925717,"user_tz":-330,"elapsed":356,"user":{"displayName":"Prateek Ghorawat","userId":"17376368182342777859"}},"outputId":"8981ae38-0b34-4d59-f7f5-d22ca4e814ee"},"execution_count":65,"outputs":[{"output_type":"execute_result","data":{"text/plain":["723188"]},"metadata":{},"execution_count":65}]},{"cell_type":"code","source":["tflite_model_file = '/content/drive/MyDrive/Colab_Notebooks/Hands_on_TinyML/01_Understanding_TF_Lite/tg_lite_model/model_pruned_dense.tflite'\n","interpreter = tf.lite.Interpreter(model_path=tflite_model_file)\n","interpreter.allocate_tensors()\n","\n","input_index = interpreter.get_input_details()[0][\"index\"]\n","output_index = interpreter.get_output_details()[0][\"index\"]\n","\n","pred_list = []\n","for images in X_test:\n","  input_data = np.array(images, dtype=np.float32)\n","\n","  input_data = input_data.reshape(1, input_data.shape[0], input_data.shape[1], 1)\n","\n","  interpreter.set_tensor(input_index, input_data)\n","  interpreter.invoke()\n","  prediction = interpreter.get_tensor(output_index)\n","  prediction = np.argmax(prediction)\n","  pred_list.append(prediction)\n","\n","accurate_count = 0\n","for index in range(len(pred_list)):\n","  if pred_list[index] == np.argmax(y_test[index]):\n","      accurate_count += 1\n","accuracy = accurate_count * 1.0 / len(pred_list)\n","\n","print('accuracy = ', accuracy)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mw2kpz5qc5pM","executionInfo":{"status":"ok","timestamp":1705159976714,"user_tz":-330,"elapsed":3009,"user":{"displayName":"Prateek Ghorawat","userId":"17376368182342777859"}},"outputId":"3a0c6e2e-cb5b-4540-b59d-69b442d60ea8"},"execution_count":66,"outputs":[{"output_type":"stream","name":"stdout","text":["accuracy =  0.9103\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"0N-fFsQxdEdH"},"execution_count":null,"outputs":[]}]}